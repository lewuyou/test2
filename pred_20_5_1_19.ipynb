{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48485,"status":"ok","timestamp":1703420845644,"user":{"displayName":"wuyou le","userId":"02064837638103088801"},"user_tz":-480},"id":"G_THiylmwOSY","outputId":"b577f14a-771b-432c-a2df-95b202256f19"},"outputs":[],"source":["# from google.colab import drive # 挂载谷歌云盘\n","# drive.mount('/content/drive')\n","# !nvidia-smi # 显示显卡信息\n","# ''' 符号%代表一直生效，！代表执行完立马结束，不会生效，所以进入目录用% '''\n","# %cd /content/drive/MyDrive/timeSerise\n","# ''' 支持的 常用命令1.ls  2.wget  3.gdoint(int(int(int(w))))n  4.mkdir  5.pwd '''\n","# !ls\n","# !pip install patool\n","# !pip install sktime\n","# !pip install reformer_pytorch"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":27556,"status":"ok","timestamp":1703420873192,"user":{"displayName":"wuyou le","userId":"02064837638103088801"},"user_tz":-480},"id":"fpLAwpfLwOSd"},"outputs":[],"source":["from data_provider.data_creat import *\n","import akshare as ak\n","from datetime import datetime\n","import random\n","import numpy as np\n","import torch\n","from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast\n","# from exp.exp_imputation import Exp_Imputation\n","# from exp.exp_short_term_forecasting import Exp_Short_Term_Forecast\n","# from exp.exp_anomaly_detection import Exp_Anomaly_Detection\n","# from exp.exp_classification import Exp_Classification\n","# from data_provider.data_creat import *\n","# import akshare as ak\n","from torch.utils.tensorboard import SummaryWriter\n","from data_provider.data_loader import Dataset_Custom\n","from torch.utils.data import DataLoader\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1703420873192,"user":{"displayName":"wuyou le","userId":"02064837638103088801"},"user_tz":-480},"id":"mB6Cl7NswOSe"},"outputs":[],"source":["class Args:\n","    '''基本配置'''\n","    # 选项：[long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]')\n","    task_name = 'long_term_forecast'\n","    model_id = 'stock_cy'\n","    des = '20240107' # 实验描述 20231210\n","    # 模型名称，选项：[Autoformer, Transformer, TimesNet]\n","    model = 'TimesNet'\n","\n","    '''数据加载'''\n","    # 数据集类型,选项：[ETTh1,ETTh2,ETTm1,ETTm2,custom,m4,PSM,MSL,SMAP,SMD,SWAT,UEA]\n","    data = 'custom'\n","    test_path = 'raw_stock_cy_300798.csv'\n","    root_path = './dataset/Stock/'\n","    data_path = 'stock_cy_all_raw.csv'\n","    # 预测任务 M:多变量预测多变量, S:单变量预测单变量, MS:多变量预测单变量\n","    features = 'MS'\n","    # 目标列名，S或MS任务中的目标特征\n","    target = 'OT'\n","    # 时间采集粒度，选项：[s:秒, t:分钟, h:小时, d:天, b:工作日, w:周, m:月]\n","    freq = 'd'\n","    # 模型检查点的位置\n","    checkpoints = './checkpoints/'\n","    \n","    '''是否训练模型'''\n","    is_training = 0 # 设置为1则进行训练，设置为0则进行测试\n","    # 测试集的比例\n","    if is_training:\n","        test_ratio = [0.1,0.1] # test测试集、valid验证集的占比\n","        pred_once = False # 是否只预测一次，用于测试集数据\n","    else:\n","        test_ratio = [0.5,0.2]\n","        data_path = test_path\n","        pred_once = True # 是否只预测一次，用于测试集数据\n","    scale = False # dataset获取的源数据是否进行归一化\n","    back_training = False # 是否从上次训练的模型继续训练\n","\n","    '''预测任务'''\n","    # 还原预测数据为原始数据\n","    inverse = scale\n","    # 输入序列长度,这是用于模型训练的输入序列的长度\n","    seq_len = 20\n","    # 开始标记长度,这是模型输出目标中有标签数据的长度，类似于滑动窗口的长度\n","    label_len = 5\n","    # 预测序列长度\n","    pred_len = 1\n","    # 季节模式（针对M4数据集）\n","    seasonal_patterns = 'Monthly'\n","\n","\n","    '''插补任务'''\n","    # 插补任务中数据丢失率\n","    mask_rate = 0.25\n","\n","    '''异常检测任务'''\n","    # 异常检测中异常点占比\n","    anomaly_ratio = 0.25\n","\n","    '''模型定义'''\n","    # 模型维度，线性层隐含神经元个数，数字越大显存用的越多\n","    d_model = 64\n","    # 前馈网络（FFN）的维度，数字越大显存用的越多\n","    d_ff = 256\n","    # TimesBlock 中傅里叶变换,频率排名前k个周期\n","    top_k = 5\n","    # Inception 中卷积核个数，用于 Inception\n","    num_kernels = 6\n","    # encoder 输入特征数\n","    enc_in = 19\n","    # decoder 输入特征数\n","    dec_in = enc_in\n","    # 输出通道数\n","    c_out = enc_in\n","    # 多头注意力机制\n","    n_heads = 8\n","    # encoder 层数，编码器层数\n","    e_layers = 2\n","    # decoder 层数，解码器层数\n","    d_layers = 1\n","    # 滑动窗口长度\n","    moving_avg = 20\n","    # 对 Q 进行采样，注意力因子数量\n","    factor = 3\n","    # 是否下采样操作 pooling，也就是对模型进行压缩\n","    distil = False\n","    # dropout 率\n","    dropout = 0.1\n","    # 时间特征嵌入方式,选项：[timeF, fixed, learned]\n","    embed = 'timeF'\n","    # 激活函数类型\n","    activation = 'gelu'\n","    # 是否输出 attention，也就是是否输出注意力权重\n","    output_attention = False\n","\n","    '''优化'''\n","    # 并行核心数\n","    num_workers = 10\n","    # 实验轮数\n","    itr = 1\n","    # 训练迭代次数\n","    train_epochs = 500\n","    # batch size 大小\n","    batch_size = 256\n","    # early stopping 机制容忍次数\n","    patience = 3\n","    # 学习率\n","    learning_rate = 0.0001\n","    # 损失函数\n","    loss = 'MSE'\n","    # 学习率下降策略\n","    lradj = 'type1'\n","    # 使用混合精度训练\n","    use_amp = False\n","\n","    '''GPU'''\n","    # 使用 gpu\n","    use_gpu = True\n","    gpu = 0\n","    # 使用多个 gpus\n","    use_multi_gpu = False\n","    # 多 gpu 的设备 id\n","    devices = '0,1,2,3'\n","\n","    '''去平稳化投影仪参数'''\n","    # 投影仪的隐藏层维度（列表）\n","    p_hidden_dims = [128, 128]\n","    # 投影仪中的隐藏层数\n","    p_hidden_layers = 2\n","  \n","    '''股票数据获取'''\n","    fuquan = 'hfq'# 设置复权方式,adjust=空选择的不复权，qfq是前复权，应该用hfq后复权来进行量化分析\n","    period = 'daily' # 拉取时间周期{'daily', 'weekly', 'monthly'}\n","    start_date = '20151201'  # 20151201   20221021  下载数据的开始日期,1就是公司上市时间\n","    end_date = '20231230'  # '20231220' 下载数据的结束日期,如果1则到最后一天,如果-1是昨天.\n","    root_path = './dataset/Stock/'\n","    \n","    # 添加预测目标Y\n","    label_n = 0 #  data['Tom_Chg'] 预测未来连续多少天的涨幅，0就是当天的涨幅。\n","    # 训练数据需要将end=lable_n，删除掉计算不出来的。预测数据不需要。\n","    end = 0 # 删除最后部分需要预测天数label_n的数据，算出来是0.\n","    zhangfu = 5  # data['OT']如果是非0，那么替换Y。涨幅大于等于5个点为1，小于5个点的为0\n","    \n","    # 是否合并全部股票数据\n","    all = True # 是否合并全部股票数据\n","    data_addzero = 21 # 当all = True时，用于训练的数据集分割，前面补0的长度 应该是seq_len + pred_len 长度\n","    \n","    # 数据修剪\n","    start = 103 # 删除前24行（start=25），因为macd算不出来\n","    # final_data_feat =  ['index', 'Volume','Tom_Chg'] # 删除不需要列的标签\n","    final_data_feat =  ['index', 'Volume','Tom_Chg','Open','Low','High'] # 删除不需要列的标签\n","    down_scaler = False # 是否对下载数据进行归一化\n","    \n","    # 此项用于预测数据，训练数据不需要\n","    add_zero_days = 0 # 未来数据填充0的天数\n","    pred_path = './dataset/Stock/pred/'\n","\n","# 创建参数对象\n","args = Args()\n","\n","# 设置随机种子以确保结果可重现\n","fix_seed = 2021\n","random.seed(fix_seed)\n","torch.manual_seed(fix_seed)\n","np.random.seed(fix_seed)\n","\n","# 创建股票数据列表\n","stock_down = ak.stock_cy_a_spot_em() # 创业板实时数据\n","stock_list = stock_down[~stock_down['名称'].str.contains(\"退|ST\") & (stock_down['流通市值'] <= 1e11) & (stock_down['总市值'] >= 45e8)] # 去除退市和ST股票\n","file_name_cy = 'Stock_list_cy.csv'# 保存数据，编码格式为utf-8\n","stock_list.to_csv(args.pred_path + file_name_cy,index=False,encoding='utf-8-sig')\n","\n","# 读取股票列表\n","stock_list = pd.read_csv(args.pred_path + file_name_cy) # 读取股票列表\n","# 将股票代码的数字转换为字符串列表\n","stock_list = [str(code) for code in stock_list['代码'].tolist()]\n","# random.shuffle(stock_list)\n","# stock_list = ['000158','300798'] # 自定义股票列表"]},{"cell_type":"markdown","metadata":{},"source":["### 初始化模型参数"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["使用 GPU.\n","系统中总共有 1 个 CUDA 设备可用。\n","使用单个 GPU.\n"]}],"source":["# 检查并设置 GPU\n","args.use_gpu = torch.cuda.is_available() and args.use_gpu\n","if args.use_gpu:\n","    print(\"使用 GPU.\")\n","    total_cuda_devices = torch.cuda.device_count()  # 获取系统中可用的 GPU 总数\n","    print(f\"系统中总共有 {total_cuda_devices} 个 CUDA 设备可用。\")\n","    if args.use_multi_gpu:\n","        args.devices = args.devices.replace(' ', '')\n","        device_ids = args.devices.split(',')\n","        args.device_ids = [int(id_) for id_ in device_ids]\n","        args.gpu = args.device_ids[0]\n","\n","        # 打印多 GPU 使用情况\n","        print(f\"使用多个GPU: {args.device_ids}\")\n","        device = torch.device(f\"cuda:{args.gpu}\" if args.use_gpu else \"cpu\")\n","        print(f\"Primary GPU (cuda:{args.gpu}) is in use.\")\n","    else:\n","        args.gpu = 0\n","        device = torch.device(\"cuda\" if args.use_gpu else \"cpu\")\n","        print(\"使用单个 GPU.\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"使用 CPU.\")\n","\n","\n","# 选择合适的实验类\n","if args.task_name == 'long_term_forecast':\n","    Exp = Exp_Long_Term_Forecast\n","# elif args.task_name == 'short_term_forecast':\n","#     Exp = Exp_Short_Term_Forecast\n","# elif args.task_name == 'imputation':\n","#     Exp = Exp_Imputation\n","# elif args.task_name == 'anomaly_detection':\n","#     Exp = Exp_Anomaly_Detection\n","# elif args.task_name == 'classification':\n","#     Exp = Exp_Classification\n","else:\n","    Exp = Exp_Long_Term_Forecast  # 默认情况\n","    \n","    \n","ii = 0\n","setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n","            args.task_name, # 任务名称\n","            args.model_id, # 模型id\n","            args.model, # 模型名称\n","            args.data, # 数据集名称\n","            args.features, # 预测任务\n","            args.seq_len, # 输入序列长度\n","            args.label_len, # 开始标记长度\n","            args.pred_len, # 预测序列长度\n","            args.d_model, # encoder 输入特征数\n","            args.n_heads, # 多头注意力机制\n","            args.e_layers, # encoder 层数\n","            args.d_layers, # decoder 层数\n","            args.d_ff, # FFN 层隐含神经元个数\n","            args.factor, # 对 Q 采样的因子数\n","            args.embed, # 时间特征嵌入方式\n","            args.distil, # 是否下采样操作 pooling\n","            args.des,  # 实验描述\n","            ii) # 实验轮数"]},{"cell_type":"markdown","metadata":{},"source":["### 载入模型"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["from models.TimesNet import Model\n","import torch\n","import os\n","\n","\n","def build_model(args):\n","    # 使用 Args 实例来构建 Model 实例\n","    model = Model(args)\n","    return model\n","\n","def acquire_device(args):\n","    if args.use_gpu:\n","        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu) if not args.use_multi_gpu else args.devices\n","        device = torch.device(f'cuda:{args.gpu}')\n","        print(f'Use GPU: cuda:{args.gpu}')\n","    else:\n","        device = torch.device('cpu')\n","        print('Use CPU')\n","    return device\n","\n","# 构建模型\n","device = acquire_device(args)\n","model = build_model(args).to(device)\n","model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth'), map_location=torch.device(device)))\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["获取数据时间为： 20151201 - 20231230\n","原始数据形状： (148, 9)\n","股票代码 301337 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (91, 9)\n","股票代码 301511 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (377, 9)\n","股票代码 301238 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (660, 9)\n","添加数据以后形状： (660, 23)\n","添加label以后数据形状: (660, 25)\n","删除指定行、列后数据形状:  (557, 20)\n","股票代码 300968 的数据保存到 raw_stock_cy_300968.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300968预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 4/591 (0.68%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (107, 9)\n","股票代码 301172 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (4, 9)\n","股票代码 301526 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1850, 9)\n","添加数据以后形状： (1850, 23)\n","添加label以后数据形状: (1850, 25)\n","删除指定行、列后数据形状:  (1747, 20)\n","股票代码 300219 的数据保存到 raw_stock_cy_300219.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300219预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 7/591 (1.18%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (125, 9)\n","股票代码 301291 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (557, 9)\n","添加数据以后形状： (557, 23)\n","添加label以后数据形状: (557, 25)\n","删除指定行、列后数据形状:  (454, 20)\n","股票代码 301061 的数据保存到 raw_stock_cy_301061.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票301061预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 9/591 (1.52%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1, 9)\n","股票代码 301566 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (130, 9)\n","股票代码 301315 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (729, 9)\n","添加数据以后形状： (729, 23)\n","添加label以后数据形状: (729, 25)\n","删除指定行、列后数据形状:  (626, 20)\n","股票代码 300925 的数据保存到 raw_stock_cy_300925.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300925预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 12/591 (2.03%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (701, 9)\n","添加数据以后形状： (701, 23)\n","添加label以后数据形状: (701, 25)\n","删除指定行、列后数据形状:  (598, 20)\n","股票代码 300941 的数据保存到 raw_stock_cy_300941.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300941预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 13/591 (2.20%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (115, 9)\n","股票代码 301456 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (16, 9)\n","股票代码 301516 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1968, 9)\n","添加数据以后形状： (1968, 23)\n","添加label以后数据形状: (1968, 25)\n","删除指定行、列后数据形状:  (1865, 20)\n","股票代码 300181 的数据保存到 raw_stock_cy_300181.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300181预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 16/591 (2.71%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (119, 9)\n","股票代码 301261 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1599, 9)\n","添加数据以后形状： (1599, 23)\n","添加label以后数据形状: (1599, 25)\n","删除指定行、列后数据形状:  (1496, 20)\n","股票代码 300663 的数据保存到 raw_stock_cy_300663.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300663预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 18/591 (3.05%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1498, 9)\n","添加数据以后形状： (1498, 23)\n","添加label以后数据形状: (1498, 25)\n","删除指定行、列后数据形状:  (1395, 20)\n","股票代码 300659 的数据保存到 raw_stock_cy_300659.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300659预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 19/591 (3.21%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1553, 9)\n","添加数据以后形状： (1553, 23)\n","添加label以后数据形状: (1553, 25)\n","删除指定行、列后数据形状:  (1450, 20)\n","股票代码 300691 的数据保存到 raw_stock_cy_300691.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300691预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 20/591 (3.38%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1874, 9)\n","添加数据以后形状： (1874, 23)\n","添加label以后数据形状: (1874, 25)\n","删除指定行、列后数据形状:  (1771, 20)\n","股票代码 300332 的数据保存到 raw_stock_cy_300332.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300332预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 21/591 (3.55%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1968, 9)\n","添加数据以后形状： (1968, 23)\n","添加label以后数据形状: (1968, 25)\n","删除指定行、列后数据形状:  (1865, 20)\n","股票代码 300174 的数据保存到 raw_stock_cy_300174.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300174预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 22/591 (3.72%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1677, 9)\n","添加数据以后形状： (1677, 23)\n","添加label以后数据形状: (1677, 25)\n","删除指定行、列后数据形状:  (1574, 20)\n","股票代码 300608 的数据保存到 raw_stock_cy_300608.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300608预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 23/591 (3.89%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1793, 9)\n","添加数据以后形状： (1793, 23)\n","添加label以后数据形状: (1793, 25)\n","删除指定行、列后数据形状:  (1690, 20)\n","股票代码 300531 的数据保存到 raw_stock_cy_300531.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300531预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 24/591 (4.06%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (838, 9)\n","添加数据以后形状： (838, 23)\n","添加label以后数据形状: (838, 25)\n","删除指定行、列后数据形状:  (735, 20)\n","股票代码 300856 的数据保存到 raw_stock_cy_300856.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300856预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 25/591 (4.23%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (527, 9)\n","添加数据以后形状： (527, 23)\n","添加label以后数据形状: (527, 25)\n","删除指定行、列后数据形状:  (424, 20)\n","股票代码 301089 的数据保存到 raw_stock_cy_301089.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票301089预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 26/591 (4.40%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1497, 9)\n","添加数据以后形状： (1497, 23)\n","添加label以后数据形状: (1497, 25)\n","删除指定行、列后数据形状:  (1394, 20)\n","股票代码 300718 的数据保存到 raw_stock_cy_300718.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300718预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 27/591 (4.57%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (494, 9)\n","股票代码 301096 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1957, 9)\n","添加数据以后形状： (1957, 23)\n","添加label以后数据形状: (1957, 25)\n","删除指定行、列后数据形状:  (1854, 20)\n","股票代码 300360 的数据保存到 raw_stock_cy_300360.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300360预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 29/591 (4.91%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1909, 9)\n","添加数据以后形状： (1909, 23)\n","添加label以后数据形状: (1909, 25)\n","删除指定行、列后数据形状:  (1806, 20)\n","股票代码 300351 的数据保存到 raw_stock_cy_300351.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300351预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 30/591 (5.08%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1755, 9)\n","添加数据以后形状： (1755, 23)\n","添加label以后数据形状: (1755, 25)\n","删除指定行、列后数据形状:  (1652, 20)\n","股票代码 300492 的数据保存到 raw_stock_cy_300492.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300492预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 31/591 (5.25%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (78, 9)\n","股票代码 301507 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (439, 9)\n","股票代码 301236 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (92, 9)\n","股票代码 301498 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (752, 9)\n","添加数据以后形状： (752, 23)\n","添加label以后数据形状: (752, 25)\n","删除指定行、列后数据形状:  (649, 20)\n","股票代码 300910 的数据保存到 raw_stock_cy_300910.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300910预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 35/591 (5.92%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (724, 9)\n","添加数据以后形状： (724, 23)\n","添加label以后数据形状: (724, 25)\n","删除指定行、列后数据形状:  (621, 20)\n","股票代码 300926 的数据保存到 raw_stock_cy_300926.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300926预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 36/591 (6.09%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1961, 9)\n","添加数据以后形状： (1961, 23)\n","添加label以后数据形状: (1961, 25)\n","删除指定行、列后数据形状:  (1858, 20)\n","股票代码 300373 的数据保存到 raw_stock_cy_300373.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300373预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 37/591 (6.26%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1679, 9)\n","添加数据以后形状： (1679, 23)\n","添加label以后数据形状: (1679, 25)\n","删除指定行、列后数据形状:  (1576, 20)\n","股票代码 300596 的数据保存到 raw_stock_cy_300596.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300596预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 38/591 (6.43%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (590, 9)\n","添加数据以后形状： (590, 23)\n","添加label以后数据形状: (590, 25)\n","删除指定行、列后数据形状:  (487, 20)\n","股票代码 301035 的数据保存到 raw_stock_cy_301035.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票301035预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 39/591 (6.60%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1884, 9)\n","添加数据以后形状： (1884, 23)\n","添加label以后数据形状: (1884, 25)\n","删除指定行、列后数据形状:  (1781, 20)\n","股票代码 300426 的数据保存到 raw_stock_cy_300426.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300426预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 40/591 (6.77%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (750, 9)\n","添加数据以后形状： (750, 23)\n","添加label以后数据形状: (750, 25)\n","删除指定行、列后数据形状:  (647, 20)\n","股票代码 300909 的数据保存到 raw_stock_cy_300909.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300909预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 41/591 (6.94%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (271, 9)\n","股票代码 301377 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (155, 9)\n","股票代码 301382 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1931, 9)\n","添加数据以后形状： (1931, 23)\n","添加label以后数据形状: (1931, 25)\n","删除指定行、列后数据形状:  (1828, 20)\n","股票代码 300093 的数据保存到 raw_stock_cy_300093.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300093预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 44/591 (7.45%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (220, 9)\n","股票代码 301358 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1023, 9)\n","添加数据以后形状： (1023, 23)\n","添加label以后数据形状: (1023, 25)\n","删除指定行、列后数据形状:  (920, 20)\n","股票代码 300793 的数据保存到 raw_stock_cy_300793.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300793预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 46/591 (7.78%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1591, 9)\n","添加数据以后形状： (1591, 23)\n","添加label以后数据形状: (1591, 25)\n","删除指定行、列后数据形状:  (1488, 20)\n","股票代码 300661 的数据保存到 raw_stock_cy_300661.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300661预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 47/591 (7.95%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (410, 9)\n","股票代码 301109 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (77, 9)\n","股票代码 301251 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (346, 9)\n","股票代码 301195 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (154, 9)\n","股票代码 301332 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1370, 9)\n","添加数据以后形状： (1370, 23)\n","添加label以后数据形状: (1370, 25)\n","删除指定行、列后数据形状:  (1267, 20)\n","股票代码 300454 的数据保存到 raw_stock_cy_300454.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300454预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 52/591 (8.80%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (380, 9)\n","股票代码 301286 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1002, 9)\n","添加数据以后形状： (1002, 23)\n","添加label以后数据形状: (1002, 25)\n","删除指定行、列后数据形状:  (899, 20)\n","股票代码 300803 的数据保存到 raw_stock_cy_300803.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300803预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 54/591 (9.14%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1963, 9)\n","添加数据以后形状： (1963, 23)\n","添加label以后数据形状: (1963, 25)\n","删除指定行、列后数据形状:  (1860, 20)\n","股票代码 300012 的数据保存到 raw_stock_cy_300012.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300012预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 55/591 (9.31%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (728, 9)\n","添加数据以后形状： (728, 23)\n","添加label以后数据形状: (728, 25)\n","删除指定行、列后数据形状:  (625, 20)\n","股票代码 300894 的数据保存到 raw_stock_cy_300894.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300894预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 56/591 (9.48%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (117, 9)\n","股票代码 301370 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (342, 9)\n","股票代码 301095 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1946, 9)\n","添加数据以后形状： (1946, 23)\n","添加label以后数据形状: (1946, 25)\n","删除指定行、列后数据形状:  (1843, 20)\n","股票代码 300073 的数据保存到 raw_stock_cy_300073.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300073预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 59/591 (9.98%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (361, 9)\n","股票代码 301312 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1968, 9)\n","添加数据以后形状： (1968, 23)\n","添加label以后数据形状: (1968, 25)\n","删除指定行、列后数据形状:  (1865, 20)\n","股票代码 300014 的数据保存到 raw_stock_cy_300014.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300014预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 61/591 (10.32%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1959, 9)\n","添加数据以后形状： (1959, 23)\n","添加label以后数据形状: (1959, 25)\n","删除指定行、列后数据形状:  (1856, 20)\n","股票代码 300482 的数据保存到 raw_stock_cy_300482.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300482预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 62/591 (10.49%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1961, 9)\n","添加数据以后形状： (1961, 23)\n","添加label以后数据形状: (1961, 25)\n","删除指定行、列后数据形状:  (1858, 20)\n","股票代码 300438 的数据保存到 raw_stock_cy_300438.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300438预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 63/591 (10.66%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (342, 9)\n","股票代码 301308 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1848, 9)\n","添加数据以后形状： (1848, 23)\n","添加label以后数据形状: (1848, 25)\n","删除指定行、列后数据形状:  (1745, 20)\n","股票代码 300146 的数据保存到 raw_stock_cy_300146.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300146预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 65/591 (11.00%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (93, 9)\n","股票代码 301510 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (653, 9)\n","添加数据以后形状： (653, 23)\n","添加label以后数据形状: (653, 25)\n","删除指定行、列后数据形状:  (550, 20)\n","股票代码 300979 的数据保存到 raw_stock_cy_300979.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300979预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 67/591 (11.34%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (815, 9)\n","添加数据以后形状： (815, 23)\n","添加label以后数据形状: (815, 25)\n","删除指定行、列后数据形状:  (712, 20)\n","股票代码 300866 的数据保存到 raw_stock_cy_300866.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300866预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 68/591 (11.51%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (815, 9)\n","添加数据以后形状： (815, 23)\n","添加label以后数据形状: (815, 25)\n","删除指定行、列后数据形状:  (712, 20)\n","股票代码 300862 的数据保存到 raw_stock_cy_300862.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300862预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 69/591 (11.68%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1279, 9)\n","添加数据以后形状： (1279, 23)\n","添加label以后数据形状: (1279, 25)\n","删除指定行、列后数据形状:  (1176, 20)\n","股票代码 300748 的数据保存到 raw_stock_cy_300748.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300748预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 70/591 (11.84%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1820, 9)\n","添加数据以后形状： (1820, 23)\n","添加label以后数据形状: (1820, 25)\n","删除指定行、列后数据形状:  (1717, 20)\n","股票代码 300142 的数据保存到 raw_stock_cy_300142.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300142预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 71/591 (12.01%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (221, 9)\n","股票代码 301260 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1968, 9)\n","添加数据以后形状： (1968, 23)\n","添加label以后数据形状: (1968, 25)\n","删除指定行、列后数据形状:  (1865, 20)\n","股票代码 300354 的数据保存到 raw_stock_cy_300354.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300354预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 73/591 (12.35%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1906, 9)\n","添加数据以后形状： (1906, 23)\n","添加label以后数据形状: (1906, 25)\n","删除指定行、列后数据形状:  (1803, 20)\n","股票代码 300284 的数据保存到 raw_stock_cy_300284.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300284预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 74/591 (12.52%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1907, 9)\n","添加数据以后形状： (1907, 23)\n","添加label以后数据形状: (1907, 25)\n","删除指定行、列后数据形状:  (1804, 20)\n","股票代码 300068 的数据保存到 raw_stock_cy_300068.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300068预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 75/591 (12.69%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1968, 9)\n","添加数据以后形状： (1968, 23)\n","添加label以后数据形状: (1968, 25)\n","删除指定行、列后数据形状:  (1865, 20)\n","股票代码 300217 的数据保存到 raw_stock_cy_300217.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300217预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 76/591 (12.86%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1960, 9)\n","添加数据以后形状： (1960, 23)\n","添加label以后数据形状: (1960, 25)\n","删除指定行、列后数据形状:  (1857, 20)\n","股票代码 300390 的数据保存到 raw_stock_cy_300390.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300390预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 77/591 (13.03%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (97, 9)\n","股票代码 301487 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (613, 9)\n","添加数据以后形状： (613, 23)\n","添加label以后数据形状: (613, 25)\n","删除指定行、列后数据形状:  (510, 20)\n","股票代码 301004 的数据保存到 raw_stock_cy_301004.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票301004预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 79/591 (13.37%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1105, 9)\n","添加数据以后形状： (1105, 23)\n","添加label以后数据形状: (1105, 25)\n","删除指定行、列后数据形状:  (1002, 20)\n","股票代码 300782 的数据保存到 raw_stock_cy_300782.csv ，形状: (200, 20)\n","test 100\n","test shape: (1, 1, 1, 1) (1, 1, 1, 1)\n","test shape: (1, 1, 1) (1, 1, 1)\n","股票300782预测结果已保存到 ./dataset/Stock/pred/result.csv 。\n","处理进度: 80/591 (13.54%)\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (206, 9)\n","股票代码 301408 的数据长度小于300,跳过此次循环。\n","获取数据时间为： 20151201 - 20231230\n","原始数据形状： (1608, 9)\n","添加数据以后形状： (1608, 23)\n","添加label以后数据形状: (1608, 25)\n","删除指定行、列后数据形状:  (1505, 20)\n","股票代码 300586 的数据保存到 raw_stock_cy_300586.csv ，形状: (200, 20)\n","test 100\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     67\u001b[0m     data_loader_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_loader)\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (batch_x, batch_y, batch_x_mark, batch_y_mark) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m data_loader_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39mpred_once:\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# 跳过除了最后一批数据之外的所有批次\u001b[39;00m\n","File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_get_data()\n\u001b[0;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queue\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n","File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n","File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\multiprocessing\\connection.py:256\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout)\n","File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\multiprocessing\\connection.py:329\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    327\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(wait([\u001b[38;5;28mself\u001b[39m], timeout))\n","File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\multiprocessing\\connection.py:878\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    875\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    876\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 878\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m _exhaustive_wait(waithandle_to_obj\u001b[38;5;241m.\u001b[39mkeys(), timeout)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n","File \u001b[1;32md:\\miniconda3\\envs\\torch\\Lib\\multiprocessing\\connection.py:810\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    808\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 810\u001b[0m     res \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWaitForMultipleObjects(L, \u001b[38;5;28;01mFalse\u001b[39;00m, timeout)\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from sklearn.preprocessing import StandardScaler\n","\n","all_data_raw = pd.DataFrame()  # 初始化一个空的 DataFrame 用于存储原始数据\n","all_data_scaled = pd.DataFrame()  # 初始化一个空的 DataFrame 用于存储标准化后的数据\n","processed_count = 0  # 初始化计数器\n","total_count = len(stock_list)  # 获取总股票数量\n","scaler = StandardScaler()\n","\n","for i in stock_list[:]:\n","    NUM = i\n","    try:\n","        # 下载原始数据\n","        raw_data = download_data(NUM, args)\n","        # 更新已处理股票数量计数器\n","        processed_count += 1\n","        if raw_data.shape[0] < 500:\n","            print(f\"股票代码 {NUM} 的数据长度小于300,跳过此次循环。\")\n","            continue\n","        \n","        # 拼接数据，添加各种参数\n","        ad_data = add_data(raw_data, args)\n","        # 添加预测标签\n","        ad_data = add_label(ad_data, args)\n","        # 删除无效数据\n","        final_data_raw = sub_data(ad_data.copy(), args)\n","\n","        # 保留最后200行\n","        final_data_raw = final_data_raw.tail(200)\n","        if args.add_zero_days:\n","            add_zeros_data = add_business_days(final_data_raw, args.add_zero_days)\n","            # Convert the list of new rows into a DataFrame and append it to the original DataFrame\n","            df_new = pd.DataFrame(add_zeros_data, columns=final_data_raw.columns)\n","            final_data_raw = pd.concat([final_data_raw, df_new]).reset_index(drop=True)\n","\n","        file_name_raw_individual = f\"raw_stock_cy_{NUM}.csv\"\n","        final_data_raw.to_csv(args.pred_path + file_name_raw_individual, index=False)\n","        print(f\"股票代码 {NUM} 的数据保存到 {file_name_raw_individual} ，形状: {final_data_raw.shape}\")\n","     \n","        # 执行预测\n","        flag='test'\n","        data_set = Dataset_Custom(\n","            root_path=args.pred_path,\n","            data_path=file_name_raw_individual,\n","            flag=flag,\n","            size=[args.seq_len, args.label_len, args.pred_len],\n","            features=args.features,\n","            target=args.target,\n","            scale = args.scale,\n","            timeenc=1,\n","            freq=args.freq,\n","            test_ratio = args.test_ratio,\n","            seasonal_patterns=args.seasonal_patterns,\n","        )\n","        print(flag, len(data_set))\n","\n","        data_loader = DataLoader(\n","            data_set,\n","            batch_size=1,\n","            shuffle=False,\n","            num_workers=args.num_workers,\n","            drop_last=True)\n","        # 最后一笔数据预测\n","        preds = []\n","        trues = []\n","        model.eval()\n","        with torch.no_grad():\n","            data_loader_length = len(data_loader)\n","            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(data_loader):\n","                if i < data_loader_length - 1 and args.pred_once:\n","                    continue  # 跳过除了最后一批数据之外的所有批次\n","                batch_x = batch_x.float().to(device)\n","                batch_y = batch_y.float().to(device)\n","\n","                batch_x_mark = batch_x_mark.float().to(device)\n","                batch_y_mark = batch_y_mark.float().to(device)\n","\n","                # decoder input \n","                dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float()\n","                dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float().to(device)\n","\n","                # 打印更多的变量\n","                # print(\"dec_inp:\", dec_inp)\n","                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","                f_dim = -1 if args.features == 'MS' else 0\n","                outputs = outputs[:, -args.pred_len:, :]\n","                batch_y = batch_y[:, -args.pred_len:, :].to(device)\n","                outputs = outputs.detach().cpu().numpy() # 将outputs转换为numpy格式\n","                batch_y = batch_y.detach().cpu().numpy() # 将batch_y转换为numpy格式\n","                if data_set.scale and args.inverse: # 如果数据进行了归一化且需要逆归一化\n","                    shape = outputs.shape\n","                    outputs = data_set.inverse_transform(outputs.squeeze(0)).reshape(shape)\n","                    batch_y = data_set.inverse_transform(batch_y.squeeze(0)).reshape(shape)\n","\n","                outputs = outputs[:, :, f_dim:]\n","                batch_y = batch_y[:, :, f_dim:]\n","                \n","                pred = outputs\n","                true = batch_y\n","                \n","                preds.append(pred)\n","                trues.append(true)\n","                \n","                preds = np.array(preds) # 将预测结果转换为numpy格式\n","                trues = np.array(trues) # 将真实结果转换为numpy格式\n","                print('test shape:', preds.shape, trues.shape)\n","                preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1]) # 将预测结果转换为三维矩阵\n","                trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n","                print('test shape:', preds.shape, trues.shape)\n","        if args.use_gpu:\n","            torch.cuda.empty_cache()\n","\n","        # 使用 flatten 方法将 preds 和 trues 转换为一维数组\n","        preds_flat = preds.flatten()\n","        trues_flat = trues.flatten()\n","\n","        # 将一维数组转换为列表\n","        preds_list = preds_flat.tolist()\n","        trues_list = trues_flat.tolist()\n","        \n","        # 计算从第n天（第1天）到n+5天（第5天）的总变化\n","        total_preds = calculate_total_change(preds_list, 1, args.pred_len)\n","        total_trues = calculate_total_change(trues_list, 1, args.pred_len)\n","        accuracy = 1 if np.sign(total_preds) == np.sign(total_trues) else 0\n","\n","        #调整\n","        accuracy_list = [1 if np.sign(preds_list[i]) == np.sign(trues_list[i]) else 0 for i in range(args.pred_len)]\n","        \n","        # 定义要写入的数据\n","        data = [NUM]\n","        for i in range(args.pred_len):\n","            data.extend([preds_list[i], trues_list[i], accuracy_list[i]])\n","        data.extend([total_preds, total_trues, accuracy])\n","\n","        # 定义列名\n","        columns = ['股票代码']\n","        for i in range(1, args.pred_len+1):\n","            columns.extend(['预测{}天涨幅'.format(i), '真实{}天涨幅'.format(i), '{}天涨幅准确率'.format(i)])\n","\n","        columns.extend(['预测累计涨跌幅', '真实累计涨跌幅', '累计涨跌幅准确率'])\n","        \n","        # 创建DataFrame\n","        df = pd.DataFrame([data], columns=columns)\n","        \n","        # 检查文件是否存在\n","        file_path = args.pred_path + 'result.csv'\n","        file_exists = os.path.isfile(file_path)\n","        # 如果文件不存在，则写入表头\n","        if not file_exists:\n","            df.to_csv(file_path, index=False, encoding='utf-8-sig')\n","        else:\n","            df.to_csv(file_path, mode='a', header=False, index=False, encoding='utf-8-sig')\n","\n","        print(f'股票{NUM}预测结果已保存到 {file_path} 。')\n","        \n","        \n","\n","    except Exception as e:\n","        print(f\"处理股票代码 {NUM} 时出现错误: {e}\")\n","        continue\n","\n","    # 计算并打印处理进度\n","    progress = processed_count / total_count\n","    print(f\"处理进度: {processed_count}/{total_count} ({progress:.2%})\")\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
